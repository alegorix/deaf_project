# ğŸ“Œ Connecter un Kinect Ã  un Raspberry Pi pour la Traduction de la Langue des Signes

## ğŸ¯ Objectif
Utiliser un Kinect avec un Raspberry Pi pour analyser une personne parlant la langue des signes et traduire les gestes en phrases en franÃ§ais.

---

## ğŸ¯ MatÃ©riel requis
- **Kinect v1 (Xbox 360) ou Kinect v2 (Xbox One)**
- **Adaptateur secteur Kinect** (obligatoire pour les modÃ¨les Xbox 360 et One)
- **Raspberry Pi 4 ou supÃ©rieur**
- **Carte microSD avec Raspberry Pi OS installÃ©**
- **CÃ¢ble USB 2.0 ou 3.0**

---

## ğŸ’ª 1. Brancher le Kinect au Raspberry Pi
### Kinect v1 (Xbox 360)
1. Connecter le Kinect Ã  son **adaptateur secteur**.
2. Relier le cÃ¢ble USB du Kinect Ã  un **port USB du Raspberry Pi**.

### Kinect v2 (Xbox One)
1. Utiliser lâ€™**adaptateur officiel Kinect v2**.
2. Brancher lâ€™adaptateur sur une **alimentation externe**.
3. Relier le Kinect via USB au Raspberry Pi.

---

## ğŸ› ï¸ 2. Installer les pilotes OpenKinect
Les pilotes **libfreenect** permettent dâ€™utiliser le Kinect v1 sous Linux.

### Ã‰tapes dâ€™installation
1. Mettre Ã  jour le Raspberry Pi :
   ```bash
   sudo apt update && sudo apt upgrade -y
   ```
2. Installer les dÃ©pendances requises :
   ```bash
   sudo apt install git cmake libusb-1.0-0-dev libturbojpeg0-dev libglfw3-dev
   ```
3. Cloner le dÃ©pÃ´t de **libfreenect** :
   ```bash
   git clone https://github.com/OpenKinect/libfreenect.git
   ```
4. Compiler et installer :
   ```bash
   cd libfreenect
   mkdir build && cd build
   cmake ..
   make
   sudo make install
   sudo ldconfig
   ```

---

## ğŸƒ 3. Tester le Kinect
VÃ©rifier si le Kinect est bien dÃ©tectÃ© :
```bash
lsusb
```
Vous devriez voir une ligne contenant **Microsoft Corp. Xbox NUI Camera**.

Tester lâ€™affichage vidÃ©o :
```bash
freenect-glview
```
Si tout fonctionne, une fenÃªtre avec lâ€™image de la camÃ©ra devrait apparaÃ®tre.

---

## ğŸ” 4. Acquisition et traitement des donnÃ©es
1. **Acquisition des donnÃ©es** :
   - Utiliser le **Kinect** pour capturer les mouvements des mains et du corps.
   - Extraire les coordonnÃ©es des articulations via **OpenNI** ou **libfreenect**.

### ğŸ“Œ Extraction avec libfreenect (Kinect v1)
libfreenect permet dâ€™accÃ©der aux donnÃ©es de profondeur mais ne gÃ¨re pas directement le suivi du squelette.

#### **Activer le capteur de profondeur**
```bash
freenect-glview
```

#### **RÃ©cupÃ©rer les donnÃ©es brutes en Python**
```python
import freenect
import cv2
import numpy as np

def get_depth():
    depth, _ = freenect.sync_get_depth()
    depth = depth.astype(np.uint8)  # Conversion pour affichage
    return depth

while True:
    depth_frame = get_depth()
    cv2.imshow('Kinect Depth', depth_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cv2.destroyAllWindows()
```

---

### ğŸ“Œ Extraction avec OpenNI (suivi des articulations)
OpenNI permet le suivi des squelettes avec NiTE.

#### **Installation dâ€™OpenNI et NiTE**
```bash
sudo apt install libopenni2-dev
```

#### **Code Python pour rÃ©cupÃ©rer les articulations**
```python
from openni import openni2
import numpy as np

openni2.initialize()
dev = openni2.Device.open_any()
depth_stream = dev.create_depth_stream()
depth_stream.start()

while True:
    frame = depth_stream.read_frame()
    frame_data = frame.get_buffer_as_uint16()
    depth_array = np.array(frame_data).reshape(480, 640)
    print("Profondeur Ã  un point (320, 240) :", depth_array[240, 320])
```
---

## ğŸ”„ 5. Conversion des gestes en texte via un moteur NLP

### **1. Mappage des signes Ã  des mots**
```python
gesture_to_text = {
    0: "Bonjour",
    1: "Merci",
    2: "Je tâ€™aime",
    3: "Comment Ã§a va ?",
}

def translate_gesture(predicted_class):
    return gesture_to_text.get(predicted_class, "Geste inconnu")
```

### **2. Assemblage des mots en phrases**
```python
recognized_gestures = [0, 3, 1]  # "Bonjour", "Comment Ã§a va ?", "Merci"
translated_words = [translate_gesture(g) for g in recognized_gestures]
sentence = " ".join(translated_words) + "."
```

### **3. AmÃ©lioration avec un modÃ¨le NLP**
```python
import spacy

nlp = spacy.load("fr_core_news_sm")

def refine_sentence(sentence):
    doc = nlp(sentence)
    return " ".join([token.text for token in doc]).capitalize()

refined_sentence = refine_sentence(sentence)
```

### **4. SynthÃ¨se vocale (facultatif)**
```python
import os
os.system(f'espeak "{refined_sentence}"')
```

---

## ğŸ“š Remarques
- **Kinect v2** nÃ©cessite **libfreenect2**, plus complexe Ã  installer sur Raspberry Pi.
- Le **suivi des squelettes** avec OpenNI/NiTE est plus prÃ©cis mais plus lourd Ã  configurer.
